{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "754KEUTqI4Vp"
   },
   "source": [
    "# Install, import and initialize\n",
    "First, we shall import basic libraries for handling dataset and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OeeYX_-5I4Vp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Set the random seeds\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tKtyH2QTI4Vs"
   },
   "source": [
    "# Import W&B and login\n",
    "Login the Weights & bias service with the given token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCepHpbpI4Vs",
    "outputId": "0967988e-c4fe-4ba8-f058-352921046d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Avni Eshchar/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "project_name = 'project-fashion-mnist'\n",
    "# %env WANDB_API_KEY='1af04e33e3d441eb82eb612e2c001eddec29bccb'\n",
    "\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hzyrUuH4I4Vt"
   },
   "source": [
    "# Download and prepare the dataset\n",
    "We download the dataset and normalize it to the 0-1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsWNya_sI4Vt",
    "outputId": "20fca74c-dce2-4b0a-eb9d-92b619db6162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (60000, 28, 28)\n",
      "Shape of y_train:  (60000,)\n",
      "Shape of x_test:  (10000, 28, 28)\n",
      "Shape of y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from class_names import class_names\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Subsetting train data and normalizing to [0., 1.]\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IsMXJfehI4Vt"
   },
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmkIqtakI4Vu"
   },
   "source": [
    "Here, we define a standard CNN (with convolution and max-pooling) in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AENBbzCvI4Vu"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = keras.layers.Dense(28, activation='relu')(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G-X7Ay93I4Vv"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775,
     "referenced_widgets": [
      "91083a5a09244c1ba70e72f450ec9377",
      "68e5267f75c44d469c1ebacd9564c6d5",
      "c9c63b6748324d028c20c5caaa3913eb",
      "07aff4a8f75b4215a2cb208393f88053",
      "8766339f9c07485aa1d5506cbfab6750",
      "87723332c8dc4dd4830983345fd04d70",
      "3fcbe5c00e104c1e91ba3c4ef7dcd621",
      "1ba9052c01b048e49e7a03732bb37832"
     ]
    },
    "id": "huamXx8XI4Vv",
    "outputId": "51d06f2b-4035-42d2-d3c9-40e8f64a8a1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2lldsa3x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">frosty-snowflake-228</strong>: <a href=\"https://wandb.ai/eshcharc/project-fashion-mnist/runs/2lldsa3x\" target=\"_blank\">https://wandb.ai/eshcharc/project-fashion-mnist/runs/2lldsa3x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230110_195142-2lldsa3x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2lldsa3x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/eshcharc/project-fashion-mnist/runs/13niyo3n\" target=\"_blank\">swift-dew-229</a></strong> to <a href=\"https://wandb.ai/eshcharc/project-fashion-mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 28)        7084      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 28)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 28)        7084      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 28)          7084      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 28)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3712      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                3612      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,146\n",
      "Trainable params: 29,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb with your project name\n",
    "run = wandb.init(project=project_name,\n",
    "                 config={\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 5,\n",
    "                     \"batch_size\": 32,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"architecture\": \"CNN\",\n",
    "                     \"dataset\": \"fashion_mnist\"\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our experiment\n",
    "\n",
    "# Initialize model like you usually do.\n",
    "keras.backend.clear_session()\n",
    "model = Model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model like you usually do.\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "3x17DaftI4Vx",
    "outputId": "4736e119-0c81-4adc-db54-1e6f0e2aebb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The data_type argument of wandb.keras.WandbCallback is deprecated and will be removed in a future release. Please use input_type instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Setting input_type = data_type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.8087 - acc: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.8087 - acc: 0.6902 - val_loss: 0.5825 - val_acc: 0.7701\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 2ms/step0s - loss: 0.5466 - acc: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.5466 - acc: 0.7930 - val_loss: 0.5292 - val_acc: 0.8040\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 2ms/step0s - loss: 0.4563 - acc: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.4563 - acc: 0.8317 - val_loss: 0.4372 - val_acc: 0.8316\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.3994 - acc: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3996 - acc: 0.8511 - val_loss: 0.3988 - val_acc: 0.8536\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 4ms/step0s - loss: 0.3559 - acc: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230110_195259-13niyo3n\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3559 - acc: 0.8677 - val_loss: 0.3588 - val_acc: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▇▇█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁▃▅▇█</td></tr><tr><td>val_loss</td><td>█▆▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.86772</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.35881</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.35585</td></tr><tr><td>val_acc</td><td>0.8714</td></tr><tr><td>val_loss</td><td>0.35881</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-dew-229</strong>: <a href=\"https://wandb.ai/eshcharc/project-fashion-mnist/runs/13niyo3n\" target=\"_blank\">https://wandb.ai/eshcharc/project-fashion-mnist/runs/13niyo3n</a><br/>Synced 6 W&B file(s), 181 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230110_195259-13niyo3n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We focus on a subset of images, since this is for human review\n",
    "val_images, val_labels = x_test[:32], y_test[:32]\n",
    "\n",
    "_ = model.fit(x_train, y_train,\n",
    "              epochs=config.epochs, \n",
    "              batch_size=config.batch_size,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[WandbCallback(data_type='image', \n",
    "                                       validation_data=(val_images, val_labels), \n",
    "                                       labels=class_names)])\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters search\n",
    "At start, there was an attempt to use W&B swip for hyper search, but it failed every time, probably of configurations issues.\n",
    "\n",
    "So, I investigated for most recommended tuners, and came up with keras-tuner as one of the them.\n",
    "\n",
    "Model is declared in a model_builder function among with hyper parameters to tweek on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)         1179776   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,306,198\n",
      "Trainable params: 1,306,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "def model_builder(hp):\n",
    "  hp_conv_units = hp.Int('hp_conv_units', min_value=32, max_value=64, step=4)\n",
    "  hp_kernel = hp.Int('hp_kernel', min_value=3, max_value=6, step=1)\n",
    "  hp_pool_size = hp.Int('hp_pool_size', min_value=3, max_value=5)\n",
    "  hp_dense_units = hp.Int('hp_dense_units', min_value=100, max_value=200, step=10)\n",
    "  hp_learning_rate = hp.Float('learning_rate', min_value=0.001, max_value=0.01, sampling=\"log\")\n",
    "  ht_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    Input(shape=input_shape),\n",
    "\n",
    "    Conv2D(filters=hp_conv_units, kernel_size=hp_kernel, activation=ht_activation, padding=\"SAME\"),\n",
    "    MaxPooling2D(pool_size=hp_pool_size, padding=\"SAME\"),\n",
    "\n",
    "    Conv2D(filters=hp_conv_units*2, kernel_size=hp_kernel*2, activation=ht_activation, padding=\"SAME\"),\n",
    "    MaxPooling2D(pool_size=hp_pool_size, padding=\"SAME\"),\n",
    "\n",
    "    Conv2D(filters=hp_conv_units*4, kernel_size=hp_kernel*4, activation=ht_activation, padding=\"SAME\"),\n",
    "    MaxPooling2D(pool_size=hp_pool_size, padding=\"SAME\"),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(units=hp_dense_units, activation='relu'),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                      from_logits=False,\n",
    "                      ignore_class=None,\n",
    "                      name='sparse_categorical_crossentropy'\n",
    "                ),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = model_builder(kt.HyperParameters())\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hyper parameters search\n",
    "In the beginning, I used the whole dataset for hyper searching params. That took quite a long time (about 30+ hours).\n",
    "\n",
    "I realized that in ML, it is always a question of available time and computer resources, which (in my case) I had neither.\n",
    "\n",
    "Actually, in hyper search, I only need to reach the best parameters' set, not to have the most trained model (which should come later).\n",
    "\n",
    "I guessed that, having working with only a subset of the data that was able to converge into a learning run, I could achieve that goal.\n",
    "\n",
    "So, multiplying dataset by a fraction of my choice, allowed my to gain some time and be able to run several tweeking cycles of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\dev\\elbit\\ML-course\\project-2\\project-fashion-mnist.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mHyperband(model_builder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhp_search\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     project_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict_fashion_item\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m es \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dev/elbit/ML-course/project-2/project-fashion-mnist.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mc \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39m./fashion_mnist.hd5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kt' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='hp_search',\n",
    "    overwrite=True,\n",
    "    project_name='predict_fashion_item')\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "mc = ModelCheckpoint('./fashion_mnist.hd5', monitor='val_accuracy', verbose=1)\n",
    "dataset_fraction = 1 / 24\n",
    "idx  = np.random.choice(len(x_train), int(len(x_train) * dataset_fraction), replace=False)\n",
    "X_samples = x_train[idx]\n",
    "y_samples = y_train[idx]\n",
    "\n",
    "tuner.search(X_samples, y_samples, epochs=10, validation_split=0.2, callbacks=[es, mc])\n",
    "\n",
    "# Get the optimal model with best params\n",
    "model = tuner.get_best_models()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with the whole dataset based on best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 275s 183ms/step - loss: 0.3428 - accuracy: 0.8765 - val_loss: 0.2915 - val_accuracy: 0.8989\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 271s 181ms/step - loss: 0.2618 - accuracy: 0.9039 - val_loss: 0.2895 - val_accuracy: 0.8989\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 276s 184ms/step - loss: 0.2230 - accuracy: 0.9170 - val_loss: 0.2565 - val_accuracy: 0.9102\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 278s 185ms/step - loss: 0.1906 - accuracy: 0.9281 - val_loss: 0.2514 - val_accuracy: 0.9113\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 280s 187ms/step - loss: 0.1665 - accuracy: 0.9385 - val_loss: 0.2434 - val_accuracy: 0.9168\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 282s 188ms/step - loss: 0.1444 - accuracy: 0.9447 - val_loss: 0.2597 - val_accuracy: 0.9187\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 281s 187ms/step - loss: 0.1327 - accuracy: 0.9504 - val_loss: 0.2705 - val_accuracy: 0.9151\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 279s 186ms/step - loss: 0.1194 - accuracy: 0.9557 - val_loss: 0.2702 - val_accuracy: 0.9148\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 282s 188ms/step - loss: 0.1108 - accuracy: 0.9581 - val_loss: 0.3003 - val_accuracy: 0.9137\n",
      "Best epoch: 6\n"
     ]
    }
   ],
   "source": [
    "# model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[es])\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 5s 64ms/step - loss: 0.3160 - accuracy: 0.9086\n",
      "test loss, test acc: [0.3160328269004822, 0.9085999727249146]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rHI0NiGzI4V8"
   },
   "source": [
    "# Save Trained Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./fashion_mnist.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./fashion_mnist.hd5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./fashion_mnist.hd5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "17dc751950550bfda40e57593d93dc3a635186a048162a8cec9e659b675d4267"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07aff4a8f75b4215a2cb208393f88053": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ba9052c01b048e49e7a03732bb37832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fcbe5c00e104c1e91ba3c4ef7dcd621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e5267f75c44d469c1ebacd9564c6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8766339f9c07485aa1d5506cbfab6750",
      "placeholder": "​",
      "style": "IPY_MODEL_87723332c8dc4dd4830983345fd04d70",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "8766339f9c07485aa1d5506cbfab6750": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87723332c8dc4dd4830983345fd04d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91083a5a09244c1ba70e72f450ec9377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68e5267f75c44d469c1ebacd9564c6d5",
       "IPY_MODEL_c9c63b6748324d028c20c5caaa3913eb"
      ],
      "layout": "IPY_MODEL_07aff4a8f75b4215a2cb208393f88053"
     }
    },
    "c9c63b6748324d028c20c5caaa3913eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fcbe5c00e104c1e91ba3c4ef7dcd621",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ba9052c01b048e49e7a03732bb37832",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
