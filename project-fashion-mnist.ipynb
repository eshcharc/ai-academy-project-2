{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "754KEUTqI4Vp"
   },
   "source": [
    "# Install, import and initialize\n",
    "First, we shall import basic libraries for handling dataset and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OeeYX_-5I4Vp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Set the random seeds\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tKtyH2QTI4Vs"
   },
   "source": [
    "# Import W&B and login\n",
    "Login the Weights & bias service with the given token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCepHpbpI4Vs",
    "outputId": "0967988e-c4fe-4ba8-f058-352921046d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Avni Eshchar/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "project_name = 'project-fashion-mnist'\n",
    "# %env WANDB_API_KEY='1af04e33e3d441eb82eb612e2c001eddec29bccb'\n",
    "\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hzyrUuH4I4Vt"
   },
   "source": [
    "# Download and prepare the dataset\n",
    "We download the dataset and normalize it to the 0-1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsWNya_sI4Vt",
    "outputId": "20fca74c-dce2-4b0a-eb9d-92b619db6162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (60000, 28, 28)\n",
      "Shape of y_train:  (60000,)\n",
      "Shape of x_test:  (10000, 28, 28)\n",
      "Shape of y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from class_names import class_names\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Subsetting train data and normalizing to [0., 1.]\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IsMXJfehI4Vt"
   },
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmkIqtakI4Vu"
   },
   "source": [
    "Here, we define a standard CNN (with convolution and max-pooling) in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AENBbzCvI4Vu"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = keras.layers.Dense(28, activation='relu')(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G-X7Ay93I4Vv"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775,
     "referenced_widgets": [
      "91083a5a09244c1ba70e72f450ec9377",
      "68e5267f75c44d469c1ebacd9564c6d5",
      "c9c63b6748324d028c20c5caaa3913eb",
      "07aff4a8f75b4215a2cb208393f88053",
      "8766339f9c07485aa1d5506cbfab6750",
      "87723332c8dc4dd4830983345fd04d70",
      "3fcbe5c00e104c1e91ba3c4ef7dcd621",
      "1ba9052c01b048e49e7a03732bb37832"
     ]
    },
    "id": "huamXx8XI4Vv",
    "outputId": "51d06f2b-4035-42d2-d3c9-40e8f64a8a1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meshcharc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/eshcharc/project-fashion-mnist/runs/3f4jtoje\" target=\"_blank\">splendid-wood-231</a></strong> to <a href=\"https://wandb.ai/eshcharc/project-fashion-mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 28)        7084      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 28)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 28)        7084      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 28)          7084      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 28)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3712      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                3612      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,146\n",
      "Trainable params: 29,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb with your project name\n",
    "run = wandb.init(project=project_name,\n",
    "                 config={\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 5,\n",
    "                     \"batch_size\": 32,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"architecture\": \"CNN\",\n",
    "                     \"dataset\": \"fashion_mnist\"\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our experiment\n",
    "\n",
    "# Initialize model like you usually do.\n",
    "keras.backend.clear_session()\n",
    "model = Model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model like you usually do.\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "3x17DaftI4Vx",
    "outputId": "4736e119-0c81-4adc-db54-1e6f0e2aebb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The data_type argument of wandb.keras.WandbCallback is deprecated and will be removed in a future release. Please use input_type instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Setting input_type = data_type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.8408 - acc: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 45s 23ms/step - loss: 0.8408 - acc: 0.6800 - val_loss: 0.6306 - val_acc: 0.7695\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.5607 - acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.5609 - acc: 0.7894 - val_loss: 0.4980 - val_acc: 0.8113\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.4578 - acc: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.4578 - acc: 0.8304 - val_loss: 0.4246 - val_acc: 0.8487\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.3872 - acc: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3872 - acc: 0.8585 - val_loss: 0.3765 - val_acc: 0.8650\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 3ms/step0s - loss: 0.3418 - acc: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (d:\\dev\\elbit\\ML-course\\project-2\\wandb\\run-20230114_101629-3f4jtoje\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3418 - acc: 0.8760 - val_loss: 0.3514 - val_acc: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▅▆▇█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇█</td></tr><tr><td>val_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.87602</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.35136</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.34178</td></tr><tr><td>val_acc</td><td>0.8724</td></tr><tr><td>val_loss</td><td>0.35136</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-wood-231</strong>: <a href=\"https://wandb.ai/eshcharc/project-fashion-mnist/runs/3f4jtoje\" target=\"_blank\">https://wandb.ai/eshcharc/project-fashion-mnist/runs/3f4jtoje</a><br/>Synced 6 W&B file(s), 181 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230114_101629-3f4jtoje\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We focus on a subset of images, since this is for human review\n",
    "val_images, val_labels = x_test[:32], y_test[:32]\n",
    "\n",
    "_ = model.fit(x_train, y_train,\n",
    "              epochs=config.epochs, \n",
    "              batch_size=config.batch_size,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[WandbCallback(data_type='image', \n",
    "                                       validation_data=(val_images, val_labels), \n",
    "                                       labels=class_names)])\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters search\n",
    "At start, there was an attempt to use W&B swip for hyper search, but it failed every time, probably of configurations issues.\n",
    "\n",
    "So, I investigated for the most recommended tuners, and came up with keras-tuner as one of them.\n",
    "\n",
    "Model is declared in a model_builder function amongst with hyper parameters to tweek on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"le_chen_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv-pool-16-2 (Sequential)  (None, 14, 14, 16)       1120      \n",
      "                                                                 \n",
      " conv-pool-32-2 (Sequential)  (None, 7, 7, 32)         6208      \n",
      "                                                                 \n",
      " conv-pool-64-2 (Sequential)  (None, 4, 4, 64)         24704     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense-1 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense-2 (Dense)             (None, 30)                7710      \n",
      "                                                                 \n",
      " prediction (Dense)          (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302,452\n",
      "Trainable params: 302,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "def conv_pool_layer(filters, kernel_size, strides, pool_size):\n",
    "    return keras.Sequential([\n",
    "        Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "               strides=strides, activation='relu', padding=\"SAME\"),\n",
    "        Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "               strides=strides, activation='relu', padding=\"SAME\"),\n",
    "        MaxPooling2D(pool_size=pool_size, padding=\"SAME\"),\n",
    "    ], name=f\"conv-pool-{filters}-{kernel_size}\")\n",
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    hp_conv_units = hp.Int('hp_conv_units', min_value=16, max_value=32, step=4)\n",
    "    hp_kernel = hp.Int('hp_kernel', min_value=2, max_value=5, step=1)\n",
    "    hp_strides = hp.Int('hp_strides', min_value=1, max_value=4)\n",
    "    hp_dropout = hp.Float('hp_dropout', min_value=0.2, max_value=0.8, sampling='log')\n",
    "    hp_pool_size = hp.Int('hp_pool_size', min_value=2, max_value=4)\n",
    "    hp_dense_units = hp.Int(\n",
    "        'hp_dense_units', min_value=256, max_value=2000, step=500)\n",
    "    hp_learning_rate = hp.Float(\n",
    "        'learning_rate', min_value=0.001, max_value=0.1, sampling='log')\n",
    "    ht_activation = hp.Choice('activation', ['relu', 'tanh', 'leaky_relu'])\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        Input(shape=input_shape, name='input'),\n",
    "\n",
    "        conv_pool_layer(hp_conv_units, hp_kernel, hp_strides, hp_pool_size),\n",
    "        conv_pool_layer(hp_conv_units*2, hp_kernel, hp_strides, hp_pool_size),\n",
    "        conv_pool_layer(hp_conv_units*4, hp_kernel, hp_strides, hp_pool_size),\n",
    "\n",
    "        Dropout(hp_dropout, name='dropout'),\n",
    "        Flatten(name='flatten'),\n",
    "\n",
    "        Dense(units=hp_dense_units, activation=ht_activation, name='dense-1'),\n",
    "        Dense(units=num_classes*3, activation=ht_activation, name='dense-2'),\n",
    "\n",
    "        Dense(units=num_classes, activation='softmax', name='prediction')\n",
    "    ], name='le_chen_net')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = model_builder(kt.HyperParameters())\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hyper parameters search\n",
    "In the beginning, I used the whole dataset for hyper searching params. That took quite a long time (about 30+ hours for 1 cycle).\n",
    "\n",
    "I realized that in ML, it is always a question of available time and computer resources, which (in my case) I had neither.\n",
    "\n",
    "Actually, in hyper search, I only need to reach the best parameters' set, not to have the most trained model (which should come later).\n",
    "\n",
    "Working with only a small equaly-distributed portion of the dataset in which the data was able to converge, could lead to the same results faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "[4 4 2 ... 6 3 5]\n",
      "Total dataset records: 60000\n",
      "Number of samples for Hyper-search: 18000 (30.0%)\n",
      "Validation split: 3600 (20.0% of samples)\n"
     ]
    }
   ],
   "source": [
    "def get_weighted_subset(x_train, y_train, frac=0.25, train_val_split=0.2):\n",
    "    num_records = len(y_train)\n",
    "    df = pd.DataFrame({ 'target': y_train })\n",
    "    df = df.groupby('target').apply(lambda x: x.sample(frac=frac))\n",
    "    df = df.droplevel('target')\n",
    "    index = df.index\n",
    "    X_sampled, y_sampled = x_train[index], y_train[index]\n",
    "    p = np.arange(len(y_sampled))\n",
    "    np.random.shuffle(p)\n",
    "    X_sampled = X_sampled[p]\n",
    "    y_sampled = y_sampled[p]\n",
    "    print(f'Total dataset records: {len(y_train)}')\n",
    "    print(f'Number of samples for Hyper-search: {len(y_sampled)} ({len(y_sampled) / num_records * 100}%)')\n",
    "\n",
    "    num_val_records = int(len(y_sampled) * train_val_split)\n",
    "    X_val_sampled, y_val_sampled = X_sampled[0:num_val_records], y_sampled[0:num_val_records]\n",
    "    X_sampled = X_sampled[num_val_records:]\n",
    "    y_sampled = y_sampled[num_val_records:]\n",
    "    \n",
    "    print(f'Validation split: {num_val_records} ({num_val_records / (num_val_records + len(X_sampled)) * 100}% of samples)')\n",
    "    return X_sampled, y_sampled, X_val_sampled, y_val_sampled\n",
    "\n",
    "X_sampled, y_sampled, X_val_sampled, y_val_sampled = get_weighted_subset(x_train, y_train, frac=0.3, train_val_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.09972222149372101\n",
      "\n",
      "Best val_accuracy So Far: 0.9069444537162781\n",
      "Total elapsed time: 01h 00m 17s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hp_search\\predict_fashion_item\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000016426C7FA00>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 4\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.5336427248999025\n",
      "hp_pool_size: 2\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0011984966344611078\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0046\n",
      "Score: 0.9069444537162781\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 24\n",
      "hp_kernel: 3\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.2079665848563499\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 1756\n",
      "learning_rate: 0.0020043172008712457\n",
      "activation: relu\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0067\n",
      "Score: 0.9002777934074402\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 3\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.6243778191588835\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0012840079280248367\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0047\n",
      "Score: 0.8999999761581421\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 4\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.5336427248999025\n",
      "hp_pool_size: 2\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0011984966344611078\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0034\n",
      "Score: 0.8961111307144165\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 3\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.6243778191588835\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0012840079280248367\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0035\n",
      "Score: 0.8924999833106995\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 24\n",
      "hp_kernel: 3\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.2079665848563499\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 1756\n",
      "learning_rate: 0.0020043172008712457\n",
      "activation: relu\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0053\n",
      "Score: 0.8899999856948853\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 28\n",
      "hp_kernel: 3\n",
      "hp_strides: 2\n",
      "hp_dropout: 0.262544645679379\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 1256\n",
      "learning_rate: 0.0014445048463088985\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 30\n",
      "tuner/initial_epoch: 10\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0068\n",
      "Score: 0.8780555725097656\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 24\n",
      "hp_kernel: 3\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.2079665848563499\n",
      "hp_pool_size: 3\n",
      "hp_dense_units: 1756\n",
      "learning_rate: 0.0020043172008712457\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8677777647972107\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 4\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.5336427248999025\n",
      "hp_pool_size: 2\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0011984966344611078\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0024\n",
      "Score: 0.8658333420753479\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hp_conv_units: 20\n",
      "hp_kernel: 4\n",
      "hp_strides: 1\n",
      "hp_dropout: 0.5336427248999025\n",
      "hp_pool_size: 2\n",
      "hp_dense_units: 256\n",
      "learning_rate: 0.0011984966344611078\n",
      "activation: leaky_relu\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.8605555295944214\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    directory='hp_search',\n",
    "    overwrite=True,\n",
    "    project_name='predict_fashion_item')\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "mc = ModelCheckpoint('./fashion_mnist.hd5', monitor='val_accuracy', verbose=1)\n",
    "\n",
    "tuner.search(X_sampled, y_sampled, validation_data=(X_val_sampled, y_val_sampled), epochs=10, callbacks=[es, mc])\n",
    "\n",
    "# Get the optimal model with best params\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "tuner.results_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model based on best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 75s 50ms/step - loss: 0.5274 - accuracy: 0.8027 - val_loss: 0.3508 - val_accuracy: 0.8708\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.3229 - accuracy: 0.8822 - val_loss: 0.3222 - val_accuracy: 0.8764\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.2807 - accuracy: 0.8962 - val_loss: 0.2647 - val_accuracy: 0.8997\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.2546 - accuracy: 0.9066 - val_loss: 0.2341 - val_accuracy: 0.9147\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 73s 49ms/step - loss: 0.2336 - accuracy: 0.9149 - val_loss: 0.2324 - val_accuracy: 0.9172\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.2190 - accuracy: 0.9192 - val_loss: 0.2187 - val_accuracy: 0.9193\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.2040 - accuracy: 0.9246 - val_loss: 0.2328 - val_accuracy: 0.9160\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.1982 - accuracy: 0.9285 - val_loss: 0.2317 - val_accuracy: 0.9181\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.1864 - accuracy: 0.9320 - val_loss: 0.2224 - val_accuracy: 0.9218\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 74s 50ms/step - loss: 0.1793 - accuracy: 0.9333 - val_loss: 0.2382 - val_accuracy: 0.9196\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 74s 49ms/step - loss: 0.1715 - accuracy: 0.9380 - val_loss: 0.2192 - val_accuracy: 0.9229\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 74s 50ms/step - loss: 0.1691 - accuracy: 0.9386 - val_loss: 0.2182 - val_accuracy: 0.9181\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 74s 50ms/step - loss: 0.1547 - accuracy: 0.9425 - val_loss: 0.2254 - val_accuracy: 0.9235\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 75s 50ms/step - loss: 0.1541 - accuracy: 0.9440 - val_loss: 0.2384 - val_accuracy: 0.9222\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 75s 50ms/step - loss: 0.1454 - accuracy: 0.9471 - val_loss: 0.2357 - val_accuracy: 0.9208\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 75s 50ms/step - loss: 0.1402 - accuracy: 0.9467 - val_loss: 0.2481 - val_accuracy: 0.9181\n",
      "Best epoch: 13\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[es])\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 2s 28ms/step - loss: 0.2658 - accuracy: 0.9140\n",
      "test loss, test acc: [0.26582542061805725, 0.9139999747276306]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rHI0NiGzI4V8"
   },
   "source": [
    "# Save Trained Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./fashion_mnist.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./fashion_mnist.hd5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./fashion_mnist.hd5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "17dc751950550bfda40e57593d93dc3a635186a048162a8cec9e659b675d4267"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07aff4a8f75b4215a2cb208393f88053": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ba9052c01b048e49e7a03732bb37832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fcbe5c00e104c1e91ba3c4ef7dcd621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e5267f75c44d469c1ebacd9564c6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8766339f9c07485aa1d5506cbfab6750",
      "placeholder": "​",
      "style": "IPY_MODEL_87723332c8dc4dd4830983345fd04d70",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "8766339f9c07485aa1d5506cbfab6750": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87723332c8dc4dd4830983345fd04d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91083a5a09244c1ba70e72f450ec9377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68e5267f75c44d469c1ebacd9564c6d5",
       "IPY_MODEL_c9c63b6748324d028c20c5caaa3913eb"
      ],
      "layout": "IPY_MODEL_07aff4a8f75b4215a2cb208393f88053"
     }
    },
    "c9c63b6748324d028c20c5caaa3913eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fcbe5c00e104c1e91ba3c4ef7dcd621",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ba9052c01b048e49e7a03732bb37832",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
